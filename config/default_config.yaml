# 파일 경로
path:
    train_path: ./dataset/train/train_new.csv       # train 데이터셋 위치
    valid_path: ./dataset/train/valid.csv           # valid.csv는 베이스라인에는 없는 파일(평가 데이터셋)
    output_dir: ./results                           # output directory
    logging_dir: ./logs                             # directory for storing logs
    MODEL_PATH : ./best_model

    test_path : ./dataset/test/test_data.csv        # test_data.csv 위치
    submission_path: ./prediction/                  # submission.csv 위치
    difference_path: ./prediction/                  # difference.csv 위치
      
    dict_label_to_num: ./code/dict_label_to_num.pkl        # label_to_num 피클파일 위치
    dict_num_to_label: ./code/dict_num_to_label.pkl        # num_to_label 피클파일 위치
      
# 파라미터
params:
    MODEL_NAME: klue/roberta-large
        
    save_total_limit: 5                             # number of total save model.
    save_steps: 500                                 # model saving step.
    num_train_epochs: 5                             # total number of training epochs
    learning_rate: .00002                           # learning_rate
    per_device_train_batch_size: 32                 # batch size per device during training
    per_device_eval_batch_size: 32                  # batch size for evaluation
    warmup_steps: 500                               # number of warmup steps for learning rate scheduler
    weight_decay: .01                               # strength of weight decay
        
    logging_steps: 100                              # log saving step.

    evaluation_strategy: steps                      # evaluation strategy to adopt during training
                                                    # `no`: No evaluation during training.
                                                    # `steps`: Evaluate every `eval_steps`.
                                                    # `epoch`: Evaluate every end of epoch
    
    seeds : 42                                    # for random seeds setting

    eval_steps: 500                               # evaluation step.
    load_best_model_at_end: true

    #Early-Stopping 파라미터
    early_stopping_patience: 3                      # 조기 중지까지의 기다리는 횟수
    early_stopping_threshold: 0.01                  # 개선의 임계값
    early_stopping_metric: eval_loss                # 평가 지표 (여기서는 eval_loss 사용)
    # early_stopping_metric: "eval_micro f1 score"  # micro f1을 사용하는 예시
    early_stopping_metric_minimize: True            # 평가 지표를 최소화해야 하는지 여부
    
    Get_Focal: True                                 # Focal Loss 적용 여부